{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f391c13f-35c4-491f-b61a-cdb46bca75ef",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55de786b-2ac6-4b24-8f18-0b2c54d02c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41051b-fcbc-4caf-8030-13df4c17e3b0",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ee0243fa-e61e-4e64-9029-b5c9c6aab30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load(\"colorectal_histology\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6420b286-c49c-4042-a5ea-8c3e50149363",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tr = list(tfds.as_numpy(ds)[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "921ee4c9-9186-4e30-86c7-3c66ea7620e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_x = np.array([i['image'] for i in ds_tr])\n",
    "ds_y = np.array([i['label'] for i in ds_tr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0b328e22-9c88-4ac4-b826-e8c784fa56e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(ds_x, ds_y, test_size=0.3, shuffle=True)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b43ec-3cd5-470b-ab4e-0dd4bac4fd52",
   "metadata": {},
   "source": [
    "## Dataset Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9dfd16d0-1d57-4761-a4d8-028a49439d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_LENGTH = x_train.shape[1]*x_train.shape[2]\n",
    "\n",
    "def one_hot_encoding(y_data):\n",
    "    y_data = y_data.astype(np.int8)\n",
    "    y_zeros = np.zeros(shape=(y_data.shape[0], 8))\n",
    "    y_zeros[np.arange(y_data.shape[0]), y_data] =  1\n",
    "    return y_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a48ca985-e03d-45d8-b1fa-b8c0c1974d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = one_hot_encoding(y_train)\n",
    "y_test = one_hot_encoding(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6cc0b1-0a15-4ad2-93ca-77f63b8211fe",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a60bb34f-fe88-409e-9558-3aeb5ca38417",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_layer = tf.keras.layers.Input(shape=(150,150,3))\n",
    "conv1 = tf.keras.layers.Conv2D(2**4, kernel_size=(3,3), padding=\"valid\", activation=\"sigmoid\")(inp_layer)\n",
    "max_p1 = tf.keras.layers.MaxPool2D()(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(2**5, kernel_size=(3,3), padding=\"valid\", activation=\"sigmoid\")(max_p1)\n",
    "max_p2 = tf.keras.layers.MaxPool2D()(conv2)\n",
    "conv3 = tf.keras.layers.Conv2D(2**6, kernel_size=(3,3), padding=\"valid\", activation=\"sigmoid\")(max_p2)\n",
    "fl = tf.keras.layers.Flatten()(conv3)\n",
    "out_layer = tf.keras.layers.Dense(8, activation=\"softmax\")(fl)\n",
    "model = tf.keras.Model(inputs=inp_layer, outputs=out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "13e08d6a-2d6c-4c31-8e9d-61976ae6d6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 148, 148, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 74, 74, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 73984)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 591880    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 615,464\n",
      "Trainable params: 615,464\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6e0dffbe-2494-4444-8717-706811e984f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=\"CategoricalCrossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e9d8dd70-c0b9-4f60-a9a2-3ab6afc287f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55/55 [==============================] - ETA: 0s - loss: 9.0960 - accuracy: 0.1217"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\engine\\training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\engine\\training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\engine\\training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\engine\\training.py\", line 1790, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 8) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\python\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileb88ieiyh.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\engine\\training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\engine\\training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\engine\\training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\engine\\training.py\", line 1790, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\cap_c\\Desktop\\python\\Lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 8) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=64, epochs=100, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4a245b48-7a37-473f-9fe6-73f3bc15960a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 8)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
